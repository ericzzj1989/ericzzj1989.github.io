<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >	
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
  @import url(https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300);
  /* @import url(https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons); */
    /* Color scheme stolen from Sergey Karayev */
    a {
    /*color: #b60a1c;*/
    color: #1772d0;
    /*color: #bd0a36;*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Roboto', sans-serif;
    font-size: 15px;
    font-weight: 300;
    }
    strong {
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    /*font-family: 'Avenir Next';*/
    font-size: 15px;
    font-weight: 400;
    }
    heading {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 24px;
    font-weight: 400;
    }
    papertitle {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 15px;
    font-weight:500;
    }
    name {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    font-weight: 400;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 140px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    .preview-wrapper {
      position: relative;
      width: 180px;
      height: 120px;
    }
    .preview-overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      opacity: 0;
      transition: opacity 0.3s;
      z-index: 1;
    }
    .preview-overlay img,
    .preview-overlay video {
      width: 100%;
      height: 100%;
      object-fit: cover;
      display: block;
    }
    .preview-image {
      width: 100%;
      height: 100%;
      display: block;
    }
  </style>
  <link rel="icon" type="image/png" href="media/preview.jpg">
  <title>Zhenjun Zhao - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="script/functions.js"></script>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="80%" valign="middle">
        <p align="center">
          <name>Zhenjun Zhao (赵祯俊)</name>
        </p>
        <p>
          I am a postdoctoral researcher at <a href="https://www.unizar.es/"><strong>University of Zaragoza</strong></a>, working with 
          <a href="https://scholar.google.com/citations?user=j_sMzokAAAAJ&hl=en">Javier Civera</a>.
        </p> 
        <p>
          I received my PhD from <a href="https://cuhk.edu.hk/english/">Chinese University of Hong Kong (CUHK)</a>, 
          under the supervision of <a href="https://scholar.google.com/citations?user=utlWXV0AAAAJ&hl=en">Ben M. Chen</a>. 
        </p>
        <p>
          My current research focuses on geometric modeling and optimization in 3D computer vision, 
          aiming to develop globally optimal and learning-augmented solutions for problems such as camera geometry estimation, Structure-from-Motion, SLAM, and visual localization.
          My long-term research goal is to build intelligent visual systems that combine geometric reasoning, optimization, and continual learning to 
          perceive and understand complex, dynamic 3D environments with high reliability and interpretability.
        </p>
        <p align=center>
          <a href="mailto:ericzzj89@gmail.com">Email</a> &nbsp;/&nbsp;
          <a href="https://scholar.google.com/citations?user=f5AEO48AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
          <a href="https://www.linkedin.com/in/zhenjun-zhao-513a3617b/"> LinkedIn</a> &nbsp;/&nbsp;
          <a href="https://twitter.com/zhenjun_zhao">Twitter</a> &nbsp;/&nbsp;
          <a href="https://bsky.app/profile/ericzzj.bsky.social">Bluesky</a> &nbsp;/&nbsp;
          <a href="https://github.com/ericzzj1989">GitHub</a>
        </p>
        </td>
        <td width="20%">
          <img src="media/profile.jpg" width="250" alt="headshot">
        </td>
      </tr>
      </table>
      <br>
      <br>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <heading>News</heading>

          <ul>
            <li><strong>07/2025</strong> Our paper <a href=""><strong>SLAM-X</strong></a> is accepted to <a href="https://acmmm2025.org/"><strong>ACM MM 2025</strong></a>!</li>
            <li><strong>06/2025</strong> Our paper <a href="https://arxiv.org/abs/2507.01439"><strong>TurboReg</strong></a> is accepted to <a href="https://iccv.thecvf.com/"><strong>ICCV 2025</strong></a>!</li>
            <li><strong>06/2025</strong> Our paper <a href=""><strong>STG-Avatar</strong></a> is accepted to <a href="https://www.iros25.org/"><strong>IROS 2025</strong></a>!</li>
            <li><strong>04/2025</strong> <a href="https://arxiv.org/abs/2505.04788"><strong>GlobustVP</strong></a> is nominated as <strong><span style="color:#c20000;">Best Paper Award Candidate</span></strong> by <a href="https://cvpr.thecvf.com/"><strong>CVPR 2025</strong></a>!</li>
            <li><strong>04/2025</strong> <b><span style="color:#c20000;">Career Update</span></b>: I start working as a postdoctoral researcher at <a href="https://www.unizar.es/"><strong>University of Zaragoza</strong></a>!</li>
            <li><strong>02/2025</strong> Our papers <a href="https://arxiv.org/abs/2505.04788"><strong>GlobustVP</strong></a> and <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.html"><strong>HeMoRa</strong></a> are accepted to <a href="https://cvpr.thecvf.com/"><strong>CVPR 2025</strong></a>!</li>
            <li><strong>07/2024</strong> Our paper <a href="https://bangyan101.github.io/GlobalPointer/"><strong>GlobalPointer</strong></a> is accepted to <a href="https://eccv2024.ecva.net/"><strong>ECCV 2024</strong></a>!</li>
            <li><strong>04/2024</strong> Our paper <a href="https://arxiv.org/abs/2404.08928"><strong>DeDoDe v2</strong></a> is accepted to <a href="https://image-matching-workshop.github.io/"><strong>CVPR 2024 Workshop</strong></a>!</li>
            <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
            <div id="old_news" style="display: none;">
              <li><strong>10/2023</strong> Our paper <a href="https://ericzzj1989.github.io/balf"><strong>BALF</strong></a> is accepted to <a href="https://wacv2024.thecvf.com/"><strong>WACV 2024</strong></a>!</li>
              <li><strong>04/2023</strong> Our paper <a href="https://ieeexplore.ieee.org/abstract/document/10124374"><strong>Hong Kong World</strong></a> is accepted to <strong>TPAMI</strong>!</li>
              <li><strong>04/2023</strong> Our paper <a href="https://ieeexplore.ieee.org/abstract/document/10240505"><strong>Benchmark for Evaluating Initialization of Visual-Inertial Odometry</strong></a> is accepted to <a href="https://ccc2023en.nankai.edu.cn/"><strong>CCC 2023</strong></a>!</li>
              <li><strong>01/2023</strong> Our paper <a href="https://arxiv.org/abs/2302.08269"><strong>SyreaNet</strong></a> is accepted to <a href="https://www.icra2023.org/"><strong>ICRA 2023</strong></a>!</li>
            </div>
          </ul>
      </table>
      <br>
      <br>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      
      <heading>Research</heading>

        <tr onmouseout="slamx_stop()" onmouseover="slamx_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id='slamx_shape'>
              <img src='media/slamx_output.png' width="180" height="120"></div>
              <img src='media/slamx_input.png' width="180" height="120"></div>
            <script type="text/javascript">
              function slamx_start() { 
                document.getElementById('slamx_shape').style.opacity = "1";
              }
              function slamx_stop() { 
                document.getElementById('slamx_shape').style.opacity = "0"; 
              }
              slamx_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://dl.acm.org/doi/abs/10.1145/3746027.3754971">
              <papertitle>
                SLAM-X: Generalizable Dynamic Removal for NeRF and Gaussian Splatting SLAM
              </papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=l8tia5AAAAAJ&hl=zh-CN">Mingrui Li</a>,
            <a href="https://doongli.github.io/">Dong Li</a>,
            <a href="https://github.com/JennHash">Sijia Hu</a>,
            <a href="https://orcid.org/0009-0005-2260-7772">Kangxu Wang</a>,
            <strong>Zhenjun Zhao</strong>,
            <a href="https://faculty.dlut.edu.cn/MMCL_WHY/en/more/726197/gzjlgd/">Hongyu Wang</a>
            <br>
            <em>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2025
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3746027.3754971">paper</a> |
            <!-- <a href="">code</a> -->
            <p></p>
            A plug-and-play module for dynamic scene handling across diverse SLAM architectures
            <p></p>
          </td>
        </tr>

        <tr onmouseout="turboreg_stop()" onmouseover="turboreg_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id='turboreg_shape'>
              <img src='media/turboreg_output.png' width="180" height="120"></div>
              <img src='media/turboreg_input.png' width="180" height="120"></div>
            <script type="text/javascript">
              function turboreg_start() { 
                document.getElementById('turboreg_shape').style.opacity = "1";
              }
              function turboreg_stop() { 
                document.getElementById('turboreg_shape').style.opacity = "0"; 
              }
              turboreg_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/2507.01439">
              <papertitle>
                TurboReg: TurboClique for Robust and Efficient Point Cloud Registration
              </papertitle>
            </a>
            <br>
            <a href="https://laka-3dv.github.io/">Shaocheng Yan</a>,
            <a href="https://shipc-ai.github.io/">Pengcheng Shi</a>,
            <strong>Zhenjun Zhao</strong>,
            <a href="https://scholar.google.com/citations?user=33RAOskAAAAJ&hl=zh-CN">Kaixin Wang</a>,
            <a href="https://orcid.org/0009-0008-1158-3316">Kuang Cao</a>,
            <a href="https://github.com/MichaelWu99-lab">Ji Wu</a>,
            <a href="https://ljy-rs.github.io/web/">Jiayuan Li</a>
            <br>
            <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2507.01439">paper</a> |
            <a href="https://github.com/Laka-3DV/TurboReg">code</a>
            <p></p>
            A highly efficient and robust point cloud registration method, supporting both CPU and GPU platforms.
            <p></p>
          </td>
        </tr>
      
        <tr onmouseout="globustvp_stop()" onmouseover="globustvp_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'globustvp_shape'>
              <img src='media/globustvp_output.png' width="180" height="120"></div>
              <img src='media/globustvp_input.png' width="180" height="120"></div>
            <script type="text/javascript">
              function globustvp_start() { 
                document.getElementById('globustvp_shape').style.opacity = "1";
              }
              function globustvp_stop() { 
                document.getElementById('globustvp_shape').style.opacity = "0"; 
              }
              globustvp_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/2505.04788">
              <papertitle>
                Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World
              </papertitle>
            </a>
            <br>
            <a href="https://bangyan101.github.io/">Bangyan Liao</a>*,
            <strong>Zhenjun Zhao*</strong>,
            <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a>,
            <a href="https://sites.google.com/view/zhouyi-joey/home">Yi Zhou</a>,
            Yingping Zeng,
            Hao Li,
            <a href="https://ethliup.github.io/">Peidong Liu</a>
            <br>
            <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025 (<b><span style="color:#c20000;">Oral, Best Paper Award Candidate</span>, top 0.48%</b>)
            <br>
            (* equal contribution)
            <br>
            <a href="https://arxiv.org/abs/2505.04788">paper</a> |
             <a href="files/globustvp_slides.pdf">slides</a> |
            <a href="files/globustvp_poster.pdf">poster</a> |
            <a href="https://github.com/wu-cvgl/GlobustVP">code</a>
            <p></p>
            A globally optimal and outlier-robust method for vanishing point (VP) estimation in a Manhattan world, using convex relaxation techniques.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="hemora_stop()" onmouseover="hemora_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'hemora_shape'>
              <img src='media/hemora_output.png' width="180" height="120"></div>
              <img src='media/hemora_input.png' width="180" height="120"></div>
            <script type="text/javascript">
              function hemora_start() { 
                document.getElementById('hemora_shape').style.opacity = "1";
              }
              function hemora_stop() { 
                document.getElementById('hemora_shape').style.opacity = "0"; 
              }
              hemora_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.html">
              <papertitle>
                HeMoRa: Unsupervised Heuristic Consensus Sampling for Robust Point Cloud Registration
              </papertitle>
            </a>
            <br>
            <a href="https://laka-3dv.github.io/">Shaocheng Yan</a>,
            <a href="https://yimingwangmingle.github.io/bio/">Yiming Wang</a>,
            <a href="https://kaiyanzhaophoenix.github.io/bio/">Kaiyan Zhao</a>,
            <a href="https://shipc-ai.github.io/">Pengcheng Shi</a>,
            <strong>Zhenjun Zhao</strong>,
            <a href="https://skyearth.org/zhangyj/">Yongjun Zhang</a>,
            <a href="https://ljy-rs.github.io/web/">Jiayuan Li</a>
            <br>
            <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
            <br>
            <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.html">paper</a> |
            <a href="files/hemora_poster.pdf">poster</a> |
            <a href="https://github.com/Laka-3DV/HeMoRa">code</a>
            <p></p>
            A learnable sampling probability distribution for matches in robust estimation, no supervision and reinforcement-inspired.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="globalpointer_stop()" onmouseover="globalpointer_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'globalpointer_shape'>
              <img src='media/globalpointer_output.png' width="180" height="120"></div>
            <img src='media/globalpointer_input.png' width="180" height="120"></div>
            <script type="text/javascript">
              function globalpointer_start() { 
                document.getElementById('globalpointer_shape').style.opacity = "1";
              }
              function globalpointer_stop() { 
                document.getElementById('globalpointer_shape').style.opacity = "0"; 
              }
              globalpointer_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/2407.13537">
              <papertitle>
                GlobalPointer: Large-Scale Plane Adjustment with Bi-Convex Relaxation
              </papertitle>
            </a>
            <br>
            <a href="https://bangyan101.github.io/">Bangyan Liao</a>*,
            <strong>Zhenjun Zhao*</strong>,
            <a href="https://chenlu-china.github.io/">Lu Chen</a>,
            <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a>,
            <a href="https://cvg.cit.tum.de/members/cremers">Daniel Cremers</a>,
            <a href="https://ethliup.github.io/">Peidong Liu</a>
            <br>
            <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
            <br>
            (* equal contribution)
            <br>
            <a href="https://arxiv.org/abs/2407.13537">paper</a> |
            <a href="https://bangyan101.github.io/GlobalPointer/">project page</a> |
            <a href="files/globalpointer_slides.pdf">slides</a> |
            <a href="https://youtu.be/XfB6DaI7EQ4?si=hipTBVDH43HFGvDf">video</a> |
            <a href="files/globalpointer_poster.pdf">poster</a> |
            <a href="https://github.com/wu-cvgl/GlobalPointer">code</a>
            <p></p>
            A globally optimal and efficient large-scale plane adjustment, using alternating minimization and convex relaxation techniques.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="dedodev2_stop()" onmouseover="dedodev2_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'dedodev2_shape'>
              <img src='media/dedodev2_teaser.png' width="180" height="120"></p></div>
              <img src='media/dedodev2_teaser.png' width="180" height="120"></p></div>
            <script type="text/javascript">
              function dedodev2_start() { 
                document.getElementById('dedodev2_shape').style.opacity = "1";
              }
              function dedodev2_stop() { 
                document.getElementById('dedodev2_shape').style.opacity = "0"; 
              }
              dedodev2_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/2404.08928">
              <papertitle>
                DeDoDe v2: Analyzing and Improving the DeDoDe Keypoint Detector
              </papertitle>
            </a>
            <br>
            <a href="https://johanedstedt.com/">Johan Edstedt</a>,
            <a href="https://georg-bn.github.io/">Georg Bökman</a>,
            <strong>Zhenjun Zhao</strong>
            <br>
            <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) Workshop on Image Matching: Local Features & Beyond</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2404.08928">paper</a> |
            <a href="files/dedodev2_slides.pdf">slides</a> |
            <a href="https://github.com/Parskatt/DeDoDe">code</a>
            <p></p>
            An improved keypoint detector built on top of DeDoDe.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="balf_stop()" onmouseover="balf_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'balf_shape'>
              <img src='media/balf_output.png' width="180" height="100"></p></div>
              <img src='media/balf_input.png' width="180" height="100"></p></div>
            <script type="text/javascript">
              function balf_start() { 
                document.getElementById('balf_shape').style.opacity = "1";
              }
              function balf_stop() { 
                document.getElementById('balf_shape').style.opacity = "0"; 
              }
              balf_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://ericzzj1989.github.io/balf">
              <papertitle>
                BALF: Simple and Efficient Blur Aware Local Feature Detector
              </papertitle>
            </a>
            <br>
            <strong>Zhenjun Zhao</strong>
            <br>
            <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2024
            <br>
            <a href="https://openaccess.thecvf.com/content/WACV2024/html/Zhao_BALF_Simple_and_Efficient_Blur_Aware_Local_Feature_Detector_WACV_2024_paper.html">paper</a> |
            <a href="https://ericzzj1989.github.io/balf">project page</a> |
            <a href="files/balf_slides.pdf">slides</a> |
            <a href="https://youtu.be/pSn80SS9mTM?si=fJPbDiHtIMrqiqSV">video</a> |
            <a href="https://github.com/ericzzj1989/BALF">code</a>
            <p></p>
            A simple yet both efficient and effective motion blur aware local feature detector.
            <p></p>
          </td>
        </tr>
          
        <tr onmouseout="vio_stop()" onmouseover="vio_start()">  
          <td width="25%">
            <div class="preview-wrapper">
              <div class="preview-overlay" id="vio_shape">
                <video muted autoplay loop playsinline>
                  <source src="media/vio_demo.mp4" type="video/mp4">
                </video>
              </div>
              <img src="media/vio_teaser.png" class="preview-image">
            </div>
            
            <script type="text/javascript">
              function vio_start() { 
                document.getElementById('vio_shape').style.opacity = "1";
              }
              function vio_stop() { 
                document.getElementById('vio_shape').style.opacity = "0"; 
              }
              vio_stop()
            </script>
          </td>

          <td valign="top" width="75%">
            <a href="https://ieeexplore.ieee.org/abstract/document/10240505">
              <papertitle>
                Benchmark for Evaluating Initialization of Visual-Inertial Odometry
              </papertitle>
            </a>
            <br>
            <strong>Zhenjun Zhao</strong>,
            <a href="https://scholar.google.com/citations?user=utlWXV0AAAAJ&hl=en">Ben M. Chen</a>
            <br>
            <em>Chinese Control Conference (<strong>CCC</strong>)</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/10240505">paper</a> |
            <a href="https://github.com/ericzzj1989/vio_initialization_evaluation">code</a>
            <p></p>
            A novel benchmark for the evaluation of the initialization of visual-inertial odometry (VIO).
            <p></p>
          </td>
        </tr>
  
        <tr onmouseout="hkworld_stop()" onmouseover="hkworld_start()">  
          <td width="25%">
            <div class="one">
              <div class="two" id = 'hkworld_shape'>
                <img src='media/hkworld_output.png' width="180" height="120">
              </div>
                <img src='media/hkworld_input.png' width="180" height="120">
            </div>
            <script type="text/javascript">
              function hkworld_start() { 
                document.getElementById('hkworld_shape').style.opacity = "1";
              }
              function hkworld_stop() { 
                document.getElementById('hkworld_shape').style.opacity = "0"; 
              }
              hkworld_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <a href="https://ieeexplore.ieee.org/abstract/document/10124374">
              <papertitle>
                Hong Kong World: Leveraging Structural Regularity for Line-based SLAM
              </papertitle>
            </a>
            <br>
            <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a>,
            <a href="https://sites.google.com/site/drjizhao/">Ji Zhao</a>,
            <a href="https://www.linkedin.com/in/jcbazin/">Jean-Charles Bazin</a>,
            <a href="https://mpil.sookmyung.ac.kr/">Pyojin Kim</a>,
            <a href="https://unist.info/">Kyungdon Joo</a>,
            <strong>Zhenjun Zhao</strong>,
            <a href="https://scholar.google.com.hk/citations?user=WzmDQTMAAAAJ&hl=en">Yun-Hui Liu</a>
            <br>
            <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/10124374">paper</a>
            <p></p>
            A novel structural model called Hong Kong world to describe the structured scenes with vertical, horizontal and sloping dominant directions.
            <p></p>
          </td>
        </tr>
    
        <tr onmouseout="syreanet_stop()" onmouseover="syreanet_start()">  
          <td width="25%">
            <div class="preview-wrapper">
              <div class="preview-overlay" id="syreanet_shape">
                <video muted autoplay loop playsinline>
                  <source src="media/syreanet_demo.mp4" type="video/mp4">
                </video>
              </div>
              <img src="media/syreanet_teaser.png" class="preview-image">
            </div>

            <script type="text/javascript">
              function syreanet_start() { 
                document.getElementById('syreanet_shape').style.opacity = "1";
              }
              function syreanet_stop() { 
                document.getElementById('syreanet_shape').style.opacity = "0"; 
              }
              syreanet_stop()
            </script>
          </td>

          <td valign="top" width="75%">
            <a href="https://arxiv.org/abs/2302.08269">
              <papertitle>
                SyreaNet: A Physically Guided Underwater Image Enhancement Framework Integrating Synthetic and Real Images
              </papertitle>
            </a>
            <br>
            <a href="https://github.com/RockWenJJ">Junjie Wen</a>,
            <a href="https://jinqiang.github.io/">Jinqiang Cui</a>,
            <strong>Zhenjun Zhao</strong>,
            <a href="https://www.linkedin.com/in/ruixin-yan-95268b300/?originalSubdomain=hk">Ruixin Yan</a>,
            <a href="https://gaozhinuswhu.com/">Zhi Gao</a>,
            <a href="https://ieeexplore.ieee.org/author/37324043000">Lihua Dou</a>,
            <a href="https://scholar.google.com/citations?user=utlWXV0AAAAJ&hl=en">Ben M. Chen</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2302.08269">paper</a> |
            <a href="files/syreanet_poster.pdf">poster</a> |
            <a href="https://github.com/RockWenJJ/SyreaNet">code</a>
            <p></p>
            A novel UIE framework combining both synthetic and real data under the guidance of the revised underwater image formation model and DA strategies.
            <p></p>
          </td>
        </tr>
    </table>
    <br>
    <br>

      <!-- Teaching -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <heading>Teaching</heading>
          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="media/cuhk_logo.jpg" width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              Co-supervisor, <strong>Undergraduate Final Year Project</strong>, 2019-2020
              <br>
              Co-supervisor, <strong>MSc Project</strong>, 2019-2020
              <br>
              Teaching Assistant, <a href="https://www.se.cuhk.edu.hk/programmes/undergraduate-programmes/engg1130-estr1006-multivariable-calculus-for-engineers/"><strong>Multivariable Calculus for Engineers</strong></a>, Spring 2021
              <br>
              Teaching Assistant, <a href="https://www.cse.cuhk.edu.hk/academics/ug-course-list/engg2720/"><strong>Complex Variables for Engineers</strong></a>, Fall 2020
              <br>
              Teaching Assistant, <strong>Probability and Statistics for Engineers</strong>, Spring 2020
              <br>
              Teaching Assistant (Lead), <strong>Introduction to Control Systems</strong>, Fall 2019
              <br>
            </td>
          </tr>
      </table>
      <br>
      <br>

      <!-- Academic Services -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <heading>Academic Services</heading>
          <tr>
            <td>
              <ul>
                <li> <strong>Conference Reviewer</strong>: CVPR, ICCV, ICML, NeurIPS, ICLR, ICRA, 3DV</li>
                <li> <strong>Journal Reviewer</strong>: TPAMI</li>
              </ul>
            </td>
          </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template adapted from <a href="https://jonbarron.info/"><font size="2">this awesome website</font></a>
        </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-116734954-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116734954-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116734954-1');
</script>
    </td>
    </tr>
  </table>
  </body>
</html>
<!--  -->
