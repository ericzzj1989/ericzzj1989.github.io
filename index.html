<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >	
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
  @import url(https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300);
  /* @import url(https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons); */
    /* Color scheme stolen from Sergey Karayev */
    a {
    /*color: #b60a1c;*/
    color: #1772d0;
    /*color: #bd0a36;*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Roboto', sans-serif;
    font-size: 15px;
    font-weight: 300;
    }
    strong {
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    /*font-family: 'Avenir Next';*/
    font-size: 15px;
    font-weight: 400;
    }
    heading {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 24px;
    font-weight: 400;
    }
    papertitle {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 15px;
    font-weight:500;
    }
    name {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    font-weight: 400;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 140px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="media/preview.jpg">
  <title>Zhenjun Zhao - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="script/functions.js"></script>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tr>
        <td width="80%" valign="middle">
        <p align="center">
          <name>Zhenjun Zhao (赵祯俊)</name>
          <!--<br>
          ruthfong at robots dot ox dot ac dot uk-->
        </p>
        <p>
          I am a postdoctoral researcher at <a href="https://www.unizar.es/"><strong>University of Zaragoza</strong></a>, working with 
          <a href="https://scholar.google.com/citations?user=j_sMzokAAAAJ&hl=en">Javier Civera</a>.
        </p> 
        <p>
          I received my PhD from <a href="https://cuhk.edu.hk/english/">Chinese University of Hong Kong (CUHK)</a>, 
          under the supervision of <a href="https://scholar.google.com/citations?user=utlWXV0AAAAJ&hl=en">Ben M. Chen</a>. 
          <!-- Before that I completed my bachelor and master degree from <a href="https://www.nuaa.edu.cn/">Nanjing University of Aeronautics and Astronautics (NUAA)</a>. -->
        </p>
        <p>
          My current research focuses on geometric modeling and optimization in 3D computer vision, 
          aiming to develop globally optimal and learning-augmented solutions for problems such as camera geometry estimation, Structure-from-Motion, SLAM, and visual localization.
          My long-term research goal is to build intelligent visual systems that combine geometric reasoning, optimization, and continual learning to 
          perceive and understand complex, dynamic 3D environments with high reliability and interpretability.
        </p>
        <!-- <p>  
          I have been fortunate to collaborate with others, including <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a> from <a href="https://www.hkust-gz.edu.cn/">HKUST (Guangzhou) </a>, <a href="https://sairlab.org/team/chenw/">Chen Wang</a> from <a href="https://engineering.buffalo.edu/computer-science-engineering.html">University at Buffalo (UB)</a>, and <a href="https://ethliup.github.io/">Peidong Liu</a> from <a href="https://en.westlake.edu.cn/">Westlake University</a>.
        </p>   -->
        <!-- <p>
          I received my M.Sc. in navigation, guidance and control from <a href="https://www.nuaa.edu.cn/">Nanjing University of Aeronautics and Astronautics (NUAA)</a>, China, in 2012. During the master, I was supervised by <a href="http://cae.nuaa.edu.cn/2018/0906/c13664a132075/page.htm">Daobo Wang</a>. Before this, I received my B.Sc. in automation from <a href="https://www.nuaa.edu.cn/">Nanjing University of Aeronautics and Astronautics (NUAA)</a>, China, in 2008. I have also spent some time at <a href="http://www.orbbec.com.cn/">Orbbec</a> in Shenzhen, China.
        </p> -->

        <!-- <p>
          I have also spent some time at <a href="https://adsc.illinois.edu">ADSC</a> and <a href="https://www.a-star.edu.sg/">A*STAR</a> in Singapore. -->
          <!-- Previously, I was a research engineer at <a href="https://adsc.illinois.edu">Advanced Digital Sciences Center (ADSC)</a>, a research center of <a href="http://illinois.edu/">University of Illinois Urbana-Champaign (UIUC)</a> based in Singapore. I was also working at Institute for Infocomm Research (I2R), <a href="https://www.a-star.edu.sg/">Agency for Science, Technology and Research (A*STAR)</a>, Singapore.  -->
        <!-- </p> -->
<!--         <p> -->
<!--           I received a Bachelors in Computer Science at <a href="https://www.harvard.edu/">Harvard University</a> and worked with Professors <a href="http://coxlab.org/">David Cox</a> and <a href="https://www.wjscheirer.com/">Walter Scheirer</a> while there. I also spent lovely summer months at <a href="https://www.microsoft.com/">Microsoft</a>, <a href="https://www.apple.com/">Apple</a>, and <a href="https://www.deshaw.com/">D.E. Shaw</a>. -->
<!--         </p> -->
        <!--<p>I'm also supported by <a href="https://brianzhang01.github.io/">this fellow</a>.
        </p>-->
        <p align=center>
          <a href="mailto:ericzzj89@gmail.com">Email</a> &nbsp;/&nbsp;
          <!-- <a href="files/CV - Zhenjun Zhao.pdf">CV</a> &nbsp|&nbsp -->
          <!--<a href="">Biography</a> &nbsp/&nbsp-->
          <a href="https://scholar.google.com/citations?user=f5AEO48AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
          <a href="https://www.linkedin.com/in/zhenjun-zhao-513a3617b/"> LinkedIn</a> &nbsp;/&nbsp;
          <a href="https://twitter.com/zhenjun_zhao">Twitter</a> &nbsp;/&nbsp;
          <a href="https://bsky.app/profile/ericzzj.bsky.social">Bluesky</a> &nbsp;/&nbsp;
          <a href="https://github.com/ericzzj1989">GitHub</a>
        </p>
        </td>
        <td width="20%">
          <img src="media/profile.jpg" width="250" alt="headshot">
          <!--<div class="one">
          <div class="two" id="headshot_image"><img src="media/color_headshot.png" width="250" alt="headshot"></div>
          <img src="media/bw_headshot.png" width="250" alt="headshot">
          </div>
          <script type="text/javascript">
          function headshot_start() {
          document.getElementById('headshot_image').style.opacity = "1";
          }
          function headshot_stop() {
          document.getElementById('headshot_image').style.opacity = "0";
          }
          filters_stop()
          </script>-->
        </td>
        <!--<td width="33%">
        <img src="media/bw_headshot.png" width="250">
        <img src="media/color_headshot.png" width="250">
        </td>-->
      </tr>
      </table>
      <br>
      <br>

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="50%" valign="middle">
          <a href="https://cuhk.edu.hk/chinese/index.html"><img src="media/cuhk_logo.jpg" width="180"></a>
        </td>
        <td width="50%" valign="middle">
          <a href="http://www.mae.cuhk.edu.hk/~usr/index.html"><img src="media/usr_logo.PNG" width="180"></a>
        </td>
        <td width="20%" valign="middle">
          <a href="https://www.pcl.ac.cn/"><img src="media/pcl_logo.jpg" width="80"></a>
        </td>
        <td width="20%" valign="middle">
          <a href="https://www.nuaa.edu.cn/"><img src="media/nuaa_logo.png" width="80"></a>
        </td>	
      </tr>
      </table> -->

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <heading>Research interests</heading>
        <tr>
          <p>
            My research work mainly lies at the intersection of robotics and 3D computer vision, with the applications to robotics, autonomous driving, virtual reality and augmented reality etc. Currently I am exploring how to best integrate machine learning techniques (i.e. mainly deep learning) with classical geometry-based 3D visual perception pipelines to improve their performance, especially under extremely challenging conditions. In particular, design algorithms that better blend geometric inductive bias and powerful data-driven approaches.
          </p>
        </tr>
      </table>
      <br>
      <br> -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <heading>News</heading>
            <ul>
              <li><strong>06/2025</strong> Our paper <a href="https://arxiv.org/abs/2507.01439"><strong>TurboReg</strong></a> is accepted to <a href="https://iccv.thecvf.com/"><strong>ICCV 2025</strong></a>!</li>
              <li><strong>06/2025</strong> Our paper <a href=""><strong>STG-Avatar</strong></a> is accepted to <a href="https://www.iros25.org/"><strong>IROS 2025</strong></a>! Please stay tuned for more details!</li>
              <li><strong>04/2025</strong> <a href="https://arxiv.org/abs/2505.04788"><strong>GlobustVP</strong></a> is nominated as <strong><span style="color:#c20000;">Best Paper Award Candidate</span></strong> by <a href="https://cvpr.thecvf.com/"><strong>CVPR 2025</strong></a>!</li>
              <li><strong>04/2025</strong> <b><span style="color:#c20000;">Career Update</span></b>: I start working as a postdoctoral researcher at <a href="https://www.unizar.es/"><strong>University of Zaragoza</strong></a>!</li>
              <li><strong>02/2025</strong> Our papers <a href="https://arxiv.org/abs/2505.04788"><strong>GlobustVP</strong></a> and <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.pdf"><strong>HeMoRa</strong></a> are accepted to <a href="https://cvpr.thecvf.com/"><strong>CVPR 2025</strong></a>!</li>
              <li><strong>07/2024</strong> Our paper <a href="https://bangyan101.github.io/GlobalPointer/"><strong>GlobalPointer</strong></a> is accepted to <a href="https://eccv2024.ecva.net/"><strong>ECCV 2024</strong></a>!</li>
              <li><strong>04/2024</strong> Our paper <a href="https://arxiv.org/abs/2404.08928"><strong>DeDoDe v2</strong></a> is accepted to <a href="https://image-matching-workshop.github.io/"><strong>CVPR 2024 Workshop</strong></a>!</li>
              <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
              <div id="old_news" style="display: none;">
              <li><strong>10/2023</strong> Our paper <a href="https://ericzzj1989.github.io/balf"><strong>BALF</strong></a> is accepted to <a href="https://wacv2024.thecvf.com/"><strong>WACV 2024</strong></a>!</li>
              <li><strong>04/2023</strong> Our paper <a href="https://ieeexplore.ieee.org/abstract/document/10124374"><strong>Hong Kong World</strong></a> is accepted to <strong>TPAMI</strong>!</li>
              <li><strong>04/2023</strong> Our paper <a href="https://ieeexplore.ieee.org/abstract/document/10240505"><strong>Benchmark for Evaluating Initialization of Visual-Inertial Odometry</strong></a> is accepted to <a href="https://ccc2023en.nankai.edu.cn/"><strong>CCC 2023</strong></a>!</li>
              <li><strong>01/2023</strong> Our paper <a href="https://arxiv.org/abs/2302.08269"><strong>SyreaNet</strong></a> is accepted to <a href="https://www.icra2023.org/"><strong>ICRA 2023</strong></a>!</li>
            </div></div>
            </ul>
      </table>
      <br>
      <br>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <heading>Research</heading>

        <tr onmouseout="turboreg_stop()" onmouseover="turboreg_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'turboreg_shape'>
              <img src='media/turboreg_output.png' width="160" height="124"></div>
              <img src='media/turboreg_input.png' width="160" height="124"></div>
            <script type="text/javascript">
            function turboreg_start() { 
            document.getElementById('turboreg_shape').style.opacity = "1";
            }
            function turboreg_stop() { 
            document.getElementById('turboreg_shape').style.opacity = "0"; 
            }
            turboreg_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2507.01439">
                <papertitle>
                  TurboReg: TurboClique for Robust and Efficient Point Cloud Registration
                </papertitle>
              </a>
          <br>
              <a href="https://laka-3dv.github.io/">Shaocheng Yan</a>,
              <a href="https://shipc-ai.github.io/">Pengcheng Shi</a>,
              <strong>Zhenjun Zhao</strong>,
              <a href="https://scholar.google.com/citations?user=33RAOskAAAAJ&hl=zh-CN">Kaixin Wang</a>,
              <a href="https://orcid.org/0009-0008-1158-3316">Kuang Cao</a>,
              <a href="https://github.com/MichaelWu99-lab">Ji Wu</a>,
              <a href="https://ljy-rs.github.io/web/">Jiayuan Li</a>
          <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2507.01439">paper</a> |
             <!-- <a href="">slides</a> | -->
            <!-- <a href="">video</a> | -->
            <!-- <a href="">poster</a> | -->
            <a href="https://github.com/Laka-3DV/TurboReg">code</a>
            <p></p>
            A highly efficient and robust point cloud registration method, supporting both CPU and GPU platforms.
            <p></p>
          </td>
        </tr>
      
        <tr onmouseout="globustvp_stop()" onmouseover="globustvp_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'globustvp_shape'>
              <img src='media/globustvp_output.png' width="160" height="124"></div>
              <img src='media/globustvp_input.png' width="160" height="124"></div>
            <script type="text/javascript">
            function globustvp_start() { 
            document.getElementById('globustvp_shape').style.opacity = "1";
            }
            function globustvp_stop() { 
            document.getElementById('globustvp_shape').style.opacity = "0"; 
            }
            globustvp_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2505.04788">
                <papertitle>
                  Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World
                </papertitle>
              </a>
          <br>
              <a href="https://bangyan101.github.io/">Bangyan Liao</a>*,
              <strong>Zhenjun Zhao*</strong>,
              <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a>,
              <a href="https://sites.google.com/view/zhouyi-joey/home">Yi Zhou</a>,
              Yingping Zeng,
              Hao Li,
              <a href="https://ethliup.github.io/">Peidong Liu</a>
          <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025 (<b><span style="color:#c20000;">Oral, Best Paper Award Candidate</span>, top 0.48%</b>)
            <br>
            (* equal contribution)
            <br>
            <a href="https://arxiv.org/abs/2505.04788">paper</a> |
             <a href="files/globustvp_slides.pdf">slides</a> |
            <!-- <a href="">video</a> | -->
            <a href="files/globustvp_poster.pdf">poster</a> |
            <a href="https://github.com/wu-cvgl/GlobustVP">code</a>
            <p></p>
            A globally optimal and outlier-robust method for vanishing point (VP) estimation in a Manhattan world, using convex relaxation techniques.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="hemora_stop()" onmouseover="hemora_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'hemora_shape'>
              <img src='media/hemora.png' width="180" height="120"></div>
              <img src='media/hemora.png' width="180" height="120"></div>
            <script type="text/javascript">
            function hemora_start() { 
            document.getElementById('hemora_shape').style.opacity = "1";
            }
            function hemora_stop() { 
            document.getElementById('hemora_shape').style.opacity = "0"; 
            }
            hemora_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.pdf">
                <papertitle>
                  HeMoRa: Unsupervised Heuristic Consensus Sampling for Robust Point Cloud Registration
                </papertitle>
              </a>
          <br>
              <a href="https://laka-3dv.github.io/">Shaocheng Yan</a>,
              <a href="https://yimingwangmingle.github.io/bio/">Yiming Wang</a>,
              <a href="https://kaiyanzhaophoenix.github.io/bio/">Kaiyan Zhao</a>,
              <a href="https://shipc-ai.github.io/">Pengcheng Shi</a>,
              <strong>Zhenjun Zhao</strong>,
              <a href="https://skyearth.org/zhangyj/">Yongjun Zhang</a>,
              <a href="https://ljy-rs.github.io/web/">Jiayuan Li</a>
          <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
            <br>
            <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.pdf">paper</a> |
            <!-- <a href="">slides</a> | -->
            <!-- <a href="">video</a> | -->
            <a href="files/hemora_poster.pdf">poster</a> |
            <a href="https://github.com/Laka-3DV/HeMoRa">code</a>
            <p></p>
            A learnable sampling probability distribution for matches in robust estimation, no supervision and reinforcement-inspired.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="globalpointer_stop()" onmouseover="globalpointer_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'globalpointer_shape'>
              <img src='media/globalpointer_output.png' width="160" height="124"></div>
            <img src='media/globalpointer_input.png' width="160" height="124"></div>
            <script type="text/javascript">
            function globalpointer_start() { 
            document.getElementById('globalpointer_shape').style.opacity = "1";
            }
            function globalpointer_stop() { 
            document.getElementById('globalpointer_shape').style.opacity = "0"; 
            }
            globalpointer_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2407.13537">
                <papertitle>
                  GlobalPointer: Large-Scale Plane Adjustment with Bi-Convex Relaxation
                </papertitle>
              </a>
          <br>
              <a href="https://bangyan101.github.io/">Bangyan Liao</a>*,
              <strong>Zhenjun Zhao*</strong>,
              <a href="https://chenlu-china.github.io/">Lu Chen</a>,
              <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a>,
              <a href="https://cvg.cit.tum.de/members/cremers">Daniel Cremers</a>,
              <a href="https://ethliup.github.io/">Peidong Liu</a>
          <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
          <br>
            (* equal contribution)
            <br>
            <a href="https://arxiv.org/abs/2407.13537">paper</a> |
            <a href="https://bangyan101.github.io/GlobalPointer/">project page</a> |
            <a href="files/globalpointer_slides.pdf">slides</a> |
            <a href="https://youtu.be/XfB6DaI7EQ4?si=hipTBVDH43HFGvDf">video</a> |
            <a href="files/globalpointer_poster.pdf">poster</a> |
            <a href="https://github.com/wu-cvgl/GlobalPointer">code</a>
            <p></p>
            A globally optimal and efficient large-scale plane adjustment, using alternating minimization and convex relaxation techniques.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="dedodev2_stop()" onmouseover="dedodev2_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'dedodev2_shape'>
              <img src='media/dedodev2_teaser.png' width="180" height="120"></p></div>
              <img src='media/dedodev2_teaser.png' width="180" height="120"></p></div>
            <script type="text/javascript">
            function dedodev2_start() { 
            document.getElementById('dedodev2_shape').style.opacity = "1";
            }
            function dedodev2_stop() { 
            document.getElementById('dedodev2_shape').style.opacity = "0"; 
            }
            dedodev2_stop()
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2404.08928">
                <papertitle>
                  DeDoDe v2: Analyzing and Improving the DeDoDe Keypoint Detector
                </papertitle>
              </a>
          <br>
              <a href="https://johanedstedt.com/">Johan Edstedt</a>,
              <a href="https://georg-bn.github.io/">Georg Bökman</a>,
              <strong>Zhenjun Zhao</strong>
          <br>
              <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) Workshop on Image Matching: Local Features & Beyond</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2404.08928">paper</a> |
            <a href="files/dedodev2_slides.pdf">slides</a> |
            <a href="https://github.com/Parskatt/DeDoDe">code</a>
            <p></p>
            An improved keypoint detector built on top of DeDoDe.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="balf_stop()" onmouseover="balf_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'balf_shape'>
              <img src='media/balf_teaser.png' width="180" height="100"></p></div>
              <img src='media/balf_teaser.png' width="180" height="100"></p></div>
            <script type="text/javascript">
            function balf_start() { 
            document.getElementById('balf_shape').style.opacity = "1";
            }
            function balf_stop() { 
            document.getElementById('balf_shape').style.opacity = "0"; 
            }
            balf_stop()
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://ericzzj1989.github.io/balf">
                <papertitle>
                  BALF: Simple and Efficient Blur Aware Local Feature Detector
                </papertitle>
              </a>
          <br>
              <strong>Zhenjun Zhao</strong>
          <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2024
            <br>
            <a href="https://openaccess.thecvf.com/content/WACV2024/html/Zhao_BALF_Simple_and_Efficient_Blur_Aware_Local_Feature_Detector_WACV_2024_paper.html">paper</a> |
            <a href="https://ericzzj1989.github.io/balf">project page</a> |
            <a href="files/balf_slides.pdf">slides</a> |
            <a href="https://youtu.be/pSn80SS9mTM?si=fJPbDiHtIMrqiqSV">video</a> |
            <a href="https://github.com/ericzzj1989/BALF">code</a>
            <p></p>
            A simple yet both efficient and effective motion blur aware local feature detector.
            <p></p>
          </td>
        </tr>
          
        <tr onmouseout="vio_stop()" onmouseover="vio_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'vio_shape'>
            <img src='media/vio_teaser.png' width="180" height="110"></p></div>
            <img src='media/vio_teaser.png' width="180" height="110"></p></div>
            <script type="text/javascript">
            function vio_start() { 
            document.getElementById('vio_shape').style.opacity = "1";
            }
            function vio_stop() { 
            document.getElementById('vio_shape').style.opacity = "0"; 
            }
            vio_stop()
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://ieeexplore.ieee.org/abstract/document/10240505">
                <papertitle>
                  Benchmark for Evaluating Initialization of Visual-Inertial Odometry
                </papertitle>
              </a>
          <br>
              <strong>Zhenjun Zhao</strong>,
              <a href="https://scholar.google.com/citations?user=utlWXV0AAAAJ&hl=en">Ben M. Chen</a>
          <br>
              <em>Chinese Control Conference (<strong>CCC</strong>)</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/10240505">paper</a> |
            <a href="https://github.com/ericzzj1989/vio_initialization_evaluation">code</a>
            <p></p>
            A novel benchmark for the evaluation of the initialization of visual-inertial odometry (VIO).
            <p></p>
          </td>
        </tr>

        <tr onmouseout="hkworld_stop()" onmouseover="hkworld_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'balf_shape'>
              <img src='media/hkworld_teaser.png' width="180" height="100"></p></div>
              <img src='media/hkworld_teaser.png' width="180" height="100"></p></div>
            <script type="text/javascript">
            function hkworld_start() { 
            document.getElementById('hkworld_shape').style.opacity = "1";
            }
            function hkworld_stop() { 
            document.getElementById('hkworld_shape').style.opacity = "0"; 
            }
            hkworld_stop()
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://ieeexplore.ieee.org/abstract/document/10124374">
                <papertitle>
                  Hong Kong World: Leveraging Structural Regularity for Line-based SLAM
                </papertitle>
              </a>
          <br>
              <a href="https://sites.google.com/view/haoangli/homepage">Haoang Li</a>,
              <a href="https://sites.google.com/site/drjizhao/">Ji Zhao</a>,
              <a href="https://www.linkedin.com/in/jcbazin/">Jean-Charles Bazin</a>,
              <a href="https://mpil.sookmyung.ac.kr/">Pyojin Kim</a>,
              <a href="https://unist.info/">Kyungdon Joo</a>,
              <strong>Zhenjun Zhao</strong>,
              <a href="https://scholar.google.com.hk/citations?user=WzmDQTMAAAAJ&hl=en">Yun-Hui Liu</a>
          <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/10124374">paper</a>
            <p></p>
            A novel structural model called Hong Kong world to describe the structured scenes with vertical, horizontal and sloping dominant directions.
            <p></p>
          </td>
        </tr>
    
        <tr onmouseout="syreanet_stop()" onmouseover="syreanet_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'syreanet_shape'>
              <img src='media/syreanet_teaser.png' width="180" height="120"></div>
              <img src='media/syreanet_teaser.png' width="180" height="120"></div>
            </div>
            <script type="text/javascript">
            function syreanet_start() { 
            document.getElementById('syreanet_shape').style.opacity = "1";
            }
            function syreanet_stop() { 
            document.getElementById('syreanet_shape').style.opacity = "0"; 
            }
            syreanet_stop()
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2302.08269">
                <papertitle>
                  SyreaNet: A Physically Guided Underwater Image Enhancement Framework Integrating Synthetic and Real Images
                </papertitle>
              </a>
          <br>
              <a href="https://github.com/RockWenJJ">Junjie Wen</a>,
              <a href="https://jinqiang.github.io/">Jinqiang Cui</a>,
              <strong>Zhenjun Zhao</strong>,
              <a href="https://www.linkedin.com/in/ruixin-yan-95268b300/?originalSubdomain=hk">Ruixin Yan</a>,
              <a href="https://gaozhinuswhu.com/"></a>Zhi Gao</a>,
              <a href="https://ieeexplore.ieee.org/author/37324043000"></a>Lihua Dou</a>,
              <a href="https://scholar.google.com/citations?user=utlWXV0AAAAJ&hl=en">Ben M. Chen</a>
          <br>
          <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2302.08269">paper</a> |
            <a href="files/syreanet_poster.pdf">poster</a> |
            <a href="https://github.com/RockWenJJ/SyreaNet">code</a>
            <p></p>
            A novel UIE framework combining both synthetic and real data under the guidance of the revised underwater image formation model and DA strategies.
            <p></p>
          </td>
        </tr>
    </table>
    <br>
    <br>

      <!-- Teaching -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <heading>Teaching</heading>
          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="media/cuhk_logo.jpg" width="180">
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Co-supervisor, <strong>Undergraduate Final Year Project</strong>, 2019-2020
                <br>
                Co-supervisor, <strong>MSc Project</strong>, 2019-2020
                <br>
                Teaching Assistant, <a href="https://www.se.cuhk.edu.hk/programmes/undergraduate-programmes/engg1130-estr1006-multivariable-calculus-for-engineers/"><strong>Multivariable Calculus for Engineers</strong></a>, Spring 2021
                <br>
                Teaching Assistant, <a href="https://www.cse.cuhk.edu.hk/academics/ug-course-list/engg2720/"><strong>Complex Variables for Engineers</strong></a>, Fall 2020
                <br>
                Teaching Assistant, <strong>Probability and Statistics for Engineers</strong>, Spring 2020
                <br>
                Teaching Assistant (Lead), <strong>Introduction to Control Systems</strong>, Fall 2019
                <br>
            </td>
          </tr>
      </table>
      <br>
      <br>

      <!-- Academic Services -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <heading>Academic Services</heading>
            <tr>
              <td>
                
                <ul>
                    <li> <strong>Conference Reviewer</strong>: CVPR, ICCV, ICML, NeurIPS, ICLR, ICRA, 3DV</li>
                    <li> <strong>Journal Reviewer</strong>: TPAMI
                </ul>
              </td>
            </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template adapted from <a href="https://jonbarron.info/"><font size="2">this awesome website</font></a>
        </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-116734954-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116734954-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116734954-1');
</script>
    </td>
    </tr>
  </table>
  </body>
</html>
<!--  -->
